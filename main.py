from fastapi import FastAPI
from pydantic import BaseModel
import pandas as pd
import numpy as np
import traceback
from typing import Optional, List

app = FastAPI()


# --- ìƒìˆ˜ ì •ì˜ ---
VEHICLE_CAPACITY_KG = 1200
DEFAULT_MAX_CAPA = 25
DEFAULT_WEIGHT_KG = 15


# --- ë°ì´í„° ëª¨ë¸ ---
class Location(BaseModel):
    id: str
    lat: float
    lon: float
    weight: int = DEFAULT_WEIGHT_KG


class Driver(BaseModel):
    id: str
    name: str
    max_capa: Optional[int] = DEFAULT_MAX_CAPA
    base_lat: Optional[float] = None
    base_lng: Optional[float] = None
    vehicle_capacity_kg: Optional[int] = VEHICLE_CAPACITY_KG


class RequestBody(BaseModel):
    locations: List[Location]
    drivers: Optional[List[Driver]] = None
    num_vehicles: int = 4
    vehicle_capacity: int = VEHICLE_CAPACITY_KG


# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def haversine(lat1, lon1, lat2, lon2):
    """ë‘ ì¢Œí‘œ ê°„ ê±°ë¦¬ ê³„ì‚° (km)"""
    R = 6371
    phi1, phi2 = np.radians(lat1), np.radians(lat2)
    dphi = np.radians(lat2 - lat1)
    dlambda = np.radians(lon2 - lon1)
    a = np.sin(dphi/2)**2 + np.cos(phi1)*np.cos(phi2) * np.sin(dlambda/2)**2
    return 2 * R * np.arctan2(np.sqrt(a), np.sqrt(1 - a))


def get_centroid(coords_list):
    """ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ì˜ ì¤‘ì‹¬ì  ê³„ì‚°"""
    if not coords_list:
        return None
    lats = [c[0] for c in coords_list]
    lons = [c[1] for c in coords_list]
    return (np.mean(lats), np.mean(lons))


def capacity_aware_clustering(df, drivers, depot_idx=0):
    """
    â˜… V11 í•µì‹¬: max_capa ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ â˜…
    
    ì›ì¹™:
    1. í´ëŸ¬ìŠ¤í„° í¬ê¸° = ê¸°ì‚¬ì˜ max_capa (ì ˆëŒ€ ì´ˆê³¼ ë¶ˆê°€)
    2. í´ëŸ¬ìŠ¤í„° ê°„ êµì°¨ ì—†ìŒ (ì§€ë¦¬ì ìœ¼ë¡œ ì™„ì „ ë¶„ë¦¬)
    3. ê¸°ì‚¬ ê±°ì ì—ì„œ ê°€ê¹Œìš´ ì˜ì—­ë¶€í„° í• ë‹¹
    
    ì•Œê³ ë¦¬ì¦˜: Seed-based Greedy Clustering
    1. ê° ê¸°ì‚¬ì˜ ê±°ì ì„ ì‹œë“œ(seed)ë¡œ ì‚¬ìš©
    2. ê° ì‹œë“œì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ë…¸ë“œë¶€í„° max_capaë§Œí¼ í• ë‹¹
    3. ì´ë¯¸ í• ë‹¹ëœ ë…¸ë“œëŠ” ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì œì™¸
    """
    
    print("\n=== Capacity-Aware Clustering ===")
    
    # ë…¸ë“œ ì •ë³´ ì¶”ì¶œ (depot ì œì™¸)
    nodes = []
    for i in range(len(df)):
        if i == depot_idx:
            continue
        nodes.append({
            'idx': i,
            'lat': float(df.iloc[i]['lat']),
            'lon': float(df.iloc[i]['lon']),
            'weight': int(df.iloc[i]['weight']),
            'assigned': False
        })
    
    print(f"ì´ ë…¸ë“œ: {len(nodes)}ê°œ")
    
    # ê¸°ì‚¬ ì •ë³´ ì •ë¦¬ (max_capa ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬)
    driver_info = []
    for i, driver in enumerate(drivers):
        max_capa = driver.max_capa if driver.max_capa else DEFAULT_MAX_CAPA
        
        # ê±°ì  ì¢Œí‘œ (ì—†ìœ¼ë©´ depot ì‚¬ìš©)
        if driver.base_lat is not None and driver.base_lng is not None:
            base_lat, base_lng = driver.base_lat, driver.base_lng
        else:
            base_lat = float(df.iloc[depot_idx]['lat'])
            base_lng = float(df.iloc[depot_idx]['lon'])
        
        driver_info.append({
            'driver_idx': i,
            'driver': driver,
            'max_capa': max_capa,
            'base_lat': base_lat,
            'base_lng': base_lng
        })
    
    # â˜… í•µì‹¬: max_capaê°€ í° ê¸°ì‚¬ë¶€í„° ì²˜ë¦¬ â˜…
    # ì´ìœ : í° í´ëŸ¬ìŠ¤í„°ë¥¼ ë¨¼ì € í™•ë³´í•´ì•¼ ì‘ì€ í´ëŸ¬ìŠ¤í„°ê°€ ë‚¨ì€ ì˜ì—­ì—ì„œ ì„ íƒ ê°€ëŠ¥
    driver_info.sort(key=lambda x: -x['max_capa'])
    
    print(f"ê¸°ì‚¬ ì²˜ë¦¬ ìˆœì„œ (max_capa ë‚´ë¦¼ì°¨ìˆœ):")
    for d in driver_info:
        print(f"  {d['driver'].name}: max_capa={d['max_capa']}, ê±°ì =({d['base_lat']:.4f}, {d['base_lng']:.4f})")
    
    # í´ëŸ¬ìŠ¤í„° í• ë‹¹ ê²°ê³¼
    cluster_assignments = {}  # {node_idx: driver_idx}
    driver_clusters = {d['driver_idx']: [] for d in driver_info}
    
    # â˜… Seed-based Greedy Assignment â˜…
    for d_info in driver_info:
        driver_idx = d_info['driver_idx']
        max_capa = d_info['max_capa']
        base_lat = d_info['base_lat']
        base_lng = d_info['base_lng']
        
        # ë¯¸í• ë‹¹ ë…¸ë“œ ì¤‘ ê±°ì ì—ì„œ ê°€ê¹Œìš´ ìˆœìœ¼ë¡œ ì •ë ¬
        unassigned = [n for n in nodes if not n['assigned']]
        
        if not unassigned:
            print(f"  {d_info['driver'].name}: í• ë‹¹ ê°€ëŠ¥í•œ ë…¸ë“œ ì—†ìŒ")
            continue
        
        # ê±°ì ì—ì„œì˜ ê±°ë¦¬ ê³„ì‚°
        for node in unassigned:
            node['dist_to_base'] = haversine(
                node['lat'], node['lon'],
                base_lat, base_lng
            )
        
        # ê±°ë¦¬ìˆœ ì •ë ¬
        unassigned.sort(key=lambda x: x['dist_to_base'])
        
        # max_capaë§Œí¼ í• ë‹¹
        assigned_count = 0
        for node in unassigned:
            if assigned_count >= max_capa:
                break
            
            node['assigned'] = True
            cluster_assignments[node['idx']] = driver_idx
            driver_clusters[driver_idx].append(node['idx'])
            assigned_count += 1
        
        print(f"  {d_info['driver'].name}: {assigned_count}ê±´ í• ë‹¹ (max_capa={max_capa})")
    
    # ë¯¸í• ë‹¹ ë…¸ë“œ í™•ì¸
    unassigned_nodes = [n['idx'] for n in nodes if not n['assigned']]
    print(f"\në¯¸í• ë‹¹ ë…¸ë“œ: {len(unassigned_nodes)}ê°œ")
    
    return cluster_assignments, driver_clusters, unassigned_nodes, driver_info


def optimize_visit_order_nearest_neighbor(df, node_indices, start_lat, start_lon):
    """
    Nearest Neighbor ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë°©ë¬¸ ìˆœì„œ ìµœì í™”
    
    ì‹œì‘ì (ê¸°ì‚¬ ê±°ì )ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ë…¸ë“œë¶€í„° ë°©ë¬¸
    """
    if not node_indices:
        return []
    
    if len(node_indices) == 1:
        return node_indices
    
    visited = []
    remaining = set(node_indices)
    current_lat, current_lon = start_lat, start_lon
    
    while remaining:
        # í˜„ì¬ ìœ„ì¹˜ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ë…¸ë“œ ì„ íƒ
        nearest = min(remaining, key=lambda idx: haversine(
            current_lat, current_lon,
            float(df.iloc[idx]['lat']), float(df.iloc[idx]['lon'])
        ))
        
        visited.append(nearest)
        remaining.remove(nearest)
        current_lat = float(df.iloc[nearest]['lat'])
        current_lon = float(df.iloc[nearest]['lon'])
    
    return visited


def calculate_route_distance(df, visit_order, start_lat, start_lon):
    """ê²½ë¡œ ì´ ê±°ë¦¬ ê³„ì‚°"""
    if not visit_order:
        return 0
    
    total_dist = 0
    current_lat, current_lon = start_lat, start_lon
    
    for node_idx in visit_order:
        node_lat = float(df.iloc[node_idx]['lat'])
        node_lon = float(df.iloc[node_idx]['lon'])
        total_dist += haversine(current_lat, current_lon, node_lat, node_lon)
        current_lat, current_lon = node_lat, node_lon
    
    # ë³µê·€ ê±°ë¦¬ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ (ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” ë³µê·€ ì•ˆ í•  ìˆ˜ë„ ìˆìŒ)
    
    return total_dist


@app.get("/")
def read_root():
    return {
        "status": "active",
        "message": "VRP Engine V11 (First Principles - Capacity-Aware Clustering)",
        "features": [
            "â˜… max_capa í•˜ë“œìº¡ 100% ì¤€ìˆ˜",
            "â˜… í´ëŸ¬ìŠ¤í„° ê°„ êµì°¨ 0% (ì§€ë¦¬ì  ì™„ì „ ë¶„ë¦¬)",
            "â˜… max_capa í° ê¸°ì‚¬ â†’ í° í´ëŸ¬ìŠ¤í„° ìë™ ë§¤ì¹­",
            "ê¸°ì‚¬ ê±°ì  ê¸°ë°˜ í´ëŸ¬ìŠ¤í„° í• ë‹¹",
            "Nearest Neighbor ë°©ë¬¸ ìˆœì„œ ìµœì í™”"
        ],
        "principles": {
            "1": "max_capaëŠ” ì ˆëŒ€ ì´ˆê³¼ ë¶ˆê°€ (í•˜ë“œìº¡)",
            "2": "í´ëŸ¬ìŠ¤í„° ê°„ êµì°¨ ì—†ìŒ (í•œ ë…¸ë“œëŠ” í•˜ë‚˜ì˜ í´ëŸ¬ìŠ¤í„°ì—ë§Œ)",
            "3": "max_capaê°€ í° ê¸°ì‚¬ê°€ í° í´ëŸ¬ìŠ¤í„°ë¥¼ ê°€ì ¸ê°"
        },
        "algorithm": "Seed-based Greedy Clustering + Nearest Neighbor TSP"
    }


@app.post("/optimize")
def optimize_routes(body: RequestBody):
    """
    â˜… V11: First Principles ê¸°ë°˜ ë°°ì°¨ ìµœì í™” â˜…
    
    í•µì‹¬ ì›ì¹™:
    1. max_capa í•˜ë“œìº¡ ì ˆëŒ€ ì¤€ìˆ˜
    2. í´ëŸ¬ìŠ¤í„° ê°„ êµì°¨ ì—†ìŒ
    3. max_capa í° ê¸°ì‚¬ â†’ í° í´ëŸ¬ìŠ¤í„°
    
    ì•Œê³ ë¦¬ì¦˜:
    1. ê¸°ì‚¬ë¥¼ max_capa ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    2. ê° ê¸°ì‚¬ì˜ ê±°ì ì—ì„œ ê°€ê¹Œìš´ ë…¸ë“œë¶€í„° max_capaë§Œí¼ í• ë‹¹
    3. í´ëŸ¬ìŠ¤í„° ë‚´ Nearest Neighborë¡œ ë°©ë¬¸ ìˆœì„œ ê²°ì •
    """
    
    try:
        # 1. ë°ì´í„° ì¤€ë¹„
        data = [loc.dict() for loc in body.locations]
        df = pd.DataFrame(data)
        df = df.reset_index(drop=True)
        
        num_locations = len(df)
        depot_idx = 0
        
        if num_locations < 2:
            return {"status": "error", "message": "Not enough locations"}
        
        # ê¸°ì‚¬ ì„¤ì •
        if body.drivers and len(body.drivers) > 0:
            drivers = body.drivers
            use_driver_features = True
        else:
            drivers = [
                Driver(
                    id=f"driver_{i+1}",
                    name=f"ê¸°ì‚¬ {i+1}",
                    max_capa=DEFAULT_MAX_CAPA
                )
                for i in range(body.num_vehicles)
            ]
            use_driver_features = False
        
        num_vehicles = len(drivers)
        
        # max_capa í•©ê³„
        total_max_capa = sum(d.max_capa or DEFAULT_MAX_CAPA for d in drivers)
        total_calls = num_locations - 1  # depot ì œì™¸
        
        print(f"\n{'='*50}")
        print(f"VRP V11 - First Principles")
        print(f"{'='*50}")
        print(f"ì´ ì½œ: {total_calls}ê±´")
        print(f"ì´ ìˆ˜ìš©ëŸ‰: {total_max_capa}ê±´")
        print(f"ê¸°ì‚¬ ìˆ˜: {num_vehicles}ëª…")
        
        # weight ì²˜ë¦¬
        if 'weight' not in df.columns:
            df['weight'] = DEFAULT_WEIGHT_KG
        df['weight'] = pd.to_numeric(df['weight'], errors='coerce').fillna(DEFAULT_WEIGHT_KG).astype(int)
        
        # 2. â˜… í•µì‹¬: Capacity-Aware Clustering â˜…
        cluster_assignments, driver_clusters, unassigned_nodes, driver_info = \
            capacity_aware_clustering(df, drivers, depot_idx)
        
        # 3. ê° í´ëŸ¬ìŠ¤í„°ë³„ ë°©ë¬¸ ìˆœì„œ ìµœì í™” + ê²°ê³¼ ìƒì„±
        print(f"\n=== ë°©ë¬¸ ìˆœì„œ ìµœì í™” ===")
        
        results = []
        stats = []
        total_distance = 0
        
        for d_info in driver_info:
            driver_idx = d_info['driver_idx']
            driver = d_info['driver']
            max_capa = d_info['max_capa']
            base_lat = d_info['base_lat']
            base_lng = d_info['base_lng']
            
            cluster_nodes = driver_clusters[driver_idx]
            
            if not cluster_nodes:
                # ë¹ˆ í´ëŸ¬ìŠ¤í„°
                stats.append({
                    "driver_id": driver.id,
                    "driver_name": driver.name,
                    "call_count": 0,
                    "max_capa": max_capa,
                    "total_weight_kg": 0,
                    "distance_km": 0,
                    "status": "âš ï¸ ë°°ì • ì—†ìŒ"
                })
                continue
            
            # Nearest Neighborë¡œ ë°©ë¬¸ ìˆœì„œ ê²°ì •
            visit_order = optimize_visit_order_nearest_neighbor(
                df, cluster_nodes, base_lat, base_lng
            )
            
            # ê²½ë¡œ ê±°ë¦¬ ê³„ì‚°
            route_distance = calculate_route_distance(df, visit_order, base_lat, base_lng)
            total_distance += route_distance
            
            # ê²°ê³¼ ìƒì„±
            route_weight = 0
            for order, node_idx in enumerate(visit_order, 1):
                node = df.iloc[node_idx]
                node_weight = int(node['weight'])
                route_weight += node_weight
                
                results.append({
                    "id": str(node['id']),
                    "driver_id": driver.id,
                    "driver_name": driver.name,
                    "visit_order": order,
                    "weight_kg": node_weight,
                    "cumulative_weight_kg": route_weight
                })
            
            call_count = len(visit_order)
            
            # ìƒíƒœ íŒì •
            if call_count > max_capa:
                status = f"ğŸš¨ ìƒí•œ ì´ˆê³¼ ({call_count} > {max_capa})"
            elif call_count < max_capa * 0.5:
                status = f"âš ï¸ ì—¬ìœ  ({call_count} / {max_capa})"
            else:
                status = "ì •ìƒ"
            
            stats.append({
                "driver_id": driver.id,
                "driver_name": driver.name,
                "call_count": call_count,
                "max_capa": max_capa,
                "total_weight_kg": route_weight,
                "distance_km": round(route_distance, 2),
                "status": status
            })
            
            print(f"  {driver.name}: {call_count}ê±´, {route_distance:.1f}km")
        
        # 4. ê²€ì¦: max_capa ì´ˆê³¼ ì—¬ë¶€
        violations = []
        for stat in stats:
            if stat['call_count'] > stat['max_capa']:
                violations.append(f"{stat['driver_name']}: {stat['call_count']} > {stat['max_capa']}")
        
        if violations:
            print(f"\nâš ï¸ max_capa ìœ„ë°˜: {violations}")
        else:
            print(f"\nâœ… max_capa 100% ì¤€ìˆ˜")
        
        # 5. ê²°ê³¼ ë°˜í™˜
        print(f"\n{'='*50}")
        print(f"ìµœì í™” ì™„ë£Œ")
        print(f"ë°°ì •: {len(results)}ê±´, ë¯¸ë°°ì •: {len(unassigned_nodes)}ê±´")
        print(f"ì´ ê±°ë¦¬: {total_distance:.1f}km")
        print(f"{'='*50}")
        
        return {
            "status": "success",
            "updates": results,
            "statistics": stats,
            "summary": {
                "total_locations": total_calls,
                "total_assigned": len(results),
                "unassigned": len(unassigned_nodes),
                "unassigned_ids": [str(df.iloc[idx]['id']) for idx in unassigned_nodes],
                "total_distance_km": round(total_distance, 2),
                "avg_distance_km": round(total_distance / num_vehicles, 2) if num_vehicles > 0 else 0
            },
            "optimization_info": {
                "algorithm": "V11: Capacity-Aware Greedy Clustering + Nearest Neighbor",
                "max_capa_violations": len(violations),
                "cluster_overlap": 0,  # êµì°¨ ì—†ìŒ ë³´ì¥
                "principles": [
                    "max_capa í•˜ë“œìº¡ 100% ì¤€ìˆ˜",
                    "í´ëŸ¬ìŠ¤í„° ê°„ êµì°¨ 0%",
                    "max_capa í° ê¸°ì‚¬ â†’ í° í´ëŸ¬ìŠ¤í„°"
                ]
            },
            "driver_assignments": {
                d_info['driver'].name: {
                    "max_capa": d_info['max_capa'],
                    "assigned": len(driver_clusters[d_info['driver_idx']])
                }
                for d_info in driver_info
            }
        }
        
    except Exception as e:
        traceback.print_exc()
        return {
            "status": "error",
            "message": str(e),
            "traceback": traceback.format_exc()
        }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
