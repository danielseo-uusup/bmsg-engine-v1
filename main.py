from fastapi import FastAPI
from pydantic import BaseModel
import pandas as pd
import numpy as np
import traceback
from typing import Optional, List

app = FastAPI()


# --- ìƒìˆ˜ ì •ì˜ ---
VEHICLE_CAPACITY_KG = 1200
DEFAULT_MAX_CAPA = 25
DEFAULT_WEIGHT_KG = 15


# --- ë°ì´í„° ëª¨ë¸ ---
class Location(BaseModel):
    id: str
    lat: float
    lon: float
    weight: int = DEFAULT_WEIGHT_KG


class Driver(BaseModel):
    id: str
    name: str
    max_capa: Optional[int] = DEFAULT_MAX_CAPA
    base_lat: Optional[float] = None
    base_lng: Optional[float] = None
    vehicle_capacity_kg: Optional[int] = VEHICLE_CAPACITY_KG


class RequestBody(BaseModel):
    locations: List[Location]
    drivers: Optional[List[Driver]] = None
    num_vehicles: int = 4
    vehicle_capacity: int = VEHICLE_CAPACITY_KG


# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def haversine(lat1, lon1, lat2, lon2):
    """ë‘ ì¢Œí‘œ ê°„ ê±°ë¦¬ ê³„ì‚° (km)"""
    R = 6371
    phi1, phi2 = np.radians(lat1), np.radians(lat2)
    dphi = np.radians(lat2 - lat1)
    dlambda = np.radians(lon2 - lon1)
    a = np.sin(dphi/2)**2 + np.cos(phi1)*np.cos(phi2) * np.sin(dlambda/2)**2
    return 2 * R * np.arctan2(np.sqrt(a), np.sqrt(1 - a))


def capacity_aware_bisection(nodes_data, capacities, depth=0):
    """
    â˜… V11.4 í•µì‹¬: Capacity-Aware Recursive Bisection â˜…
    
    ì›ì¹™:
    1. ë…¸ë“œë“¤ì„ ê²½ë„/ìœ„ë„ ê¸°ì¤€ìœ¼ë¡œ "ì„ ì„ ê·¸ì–´" ë¶„í• 
    2. ë¶„í•  ë¹„ìœ¨ì€ capacitiesì— ë§ê²Œ ì¡°ì •
    3. í•œ ì˜ì—­ì´ ë‹¤ë¥¸ ì˜ì—­ì„ ê°ì‹¸ëŠ” ê²ƒ ë¶ˆê°€ëŠ¥ (ë¬¼ë¦¬ì ìœ¼ë¡œ)
    
    Args:
        nodes_data: [{'idx': int, 'lat': float, 'lon': float}, ...]
        capacities: [20, 20, 20, 13] - ê° í´ëŸ¬ìŠ¤í„°ê°€ ê°€ì ¸ì•¼ í•  í¬ê¸°
    
    Returns:
        [cluster0_nodes, cluster1_nodes, ...]
    """
    
    n_clusters = len(capacities)
    
    # ì¢…ë£Œ ì¡°ê±´: í´ëŸ¬ìŠ¤í„° 1ê°œ
    if n_clusters == 1:
        return [nodes_data]
    
    if len(nodes_data) == 0:
        return [[] for _ in range(n_clusters)]
    
    # ìœ„ë„/ê²½ë„ ë²”ìœ„ ê³„ì‚°
    lats = [n['lat'] for n in nodes_data]
    lons = [n['lon'] for n in nodes_data]
    
    lat_range = max(lats) - min(lats)
    lon_range = max(lons) - min(lons)
    
    # ë” ë„“ì€ ì¶•ìœ¼ë¡œ ë¶„í•  (ì§ê´€ì ì¸ ê²½ê³„ ìƒì„±)
    if lat_range >= lon_range:
        # ìœ„ë„ ê¸°ì¤€ ë¶„í•  (ë‚¨ë¶)
        sorted_nodes = sorted(nodes_data, key=lambda n: n['lat'])
        axis = 'lat'
    else:
        # ê²½ë„ ê¸°ì¤€ ë¶„í•  (ë™ì„œ)
        sorted_nodes = sorted(nodes_data, key=lambda n: n['lon'])
        axis = 'lon'
    
    # í´ëŸ¬ìŠ¤í„°ë¥¼ ë‘ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
    left_clusters = n_clusters // 2
    right_clusters = n_clusters - left_clusters
    
    left_capacities = capacities[:left_clusters]
    right_capacities = capacities[left_clusters:]
    
    # ë¶„í•  ë¹„ìœ¨ ê³„ì‚° (capacity ë¹„ìœ¨ì— ë”°ë¼)
    total_left_cap = sum(left_capacities)
    total_right_cap = sum(right_capacities)
    total_cap = total_left_cap + total_right_cap
    
    # ë¶„í•  ìœ„ì¹˜: capacity ë¹„ìœ¨ì— ë§ê²Œ
    split_ratio = total_left_cap / total_cap
    split_idx = int(len(sorted_nodes) * split_ratio)
    
    # ìµœì†Œ 1ê°œëŠ” ê° ê·¸ë£¹ì—
    split_idx = max(1, min(split_idx, len(sorted_nodes) - 1))
    
    left_nodes = sorted_nodes[:split_idx]
    right_nodes = sorted_nodes[split_idx:]
    
    indent = "  " * depth
    print(f"{indent}ë¶„í•  ({axis}): ì™¼ìª½ {len(left_nodes)}ê°œ (cap={total_left_cap}), ì˜¤ë¥¸ìª½ {len(right_nodes)}ê°œ (cap={total_right_cap})")
    
    # ì¬ê·€ í˜¸ì¶œ
    left_result = capacity_aware_bisection(left_nodes, left_capacities, depth + 1)
    right_result = capacity_aware_bisection(right_nodes, right_capacities, depth + 1)
    
    return left_result + right_result


def assign_clusters_to_drivers(clusters, drivers, df, depot_idx=0):
    """
    â˜… V11.4: í´ëŸ¬ìŠ¤í„°-ê¸°ì‚¬ ë§¤ì¹­ â˜…
    
    ì›ì¹™:
    - í´ëŸ¬ìŠ¤í„° í¬ê¸°ì™€ ê¸°ì‚¬ max_capaê°€ ì´ë¯¸ ë§ì¶°ì ¸ ìˆìŒ
    - ê¸°ì‚¬ ê±°ì ê³¼ í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ ê±°ë¦¬ë¡œ ìµœì  ë§¤ì¹­
    """
    
    print("\n=== 2ë‹¨ê³„: í´ëŸ¬ìŠ¤í„°-ê¸°ì‚¬ ë§¤ì¹­ ===")
    
    n_clusters = len(clusters)
    n_drivers = len(drivers)
    
    # ê¸°ì‚¬ ì •ë³´
    driver_info = []
    for i, driver in enumerate(drivers):
        max_capa = driver.max_capa if driver.max_capa else DEFAULT_MAX_CAPA
        base_lat = driver.base_lat if driver.base_lat else float(df.iloc[depot_idx]['lat'])
        base_lng = driver.base_lng if driver.base_lng else float(df.iloc[depot_idx]['lon'])
        
        driver_info.append({
            'driver_idx': i,
            'driver': driver,
            'max_capa': max_capa,
            'base_lat': base_lat,
            'base_lng': base_lng
        })
    
    # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì  ê³„ì‚°
    cluster_centers = []
    for i, cluster in enumerate(clusters):
        if cluster:
            center_lat = np.mean([n['lat'] for n in cluster])
            center_lon = np.mean([n['lon'] for n in cluster])
        else:
            center_lat, center_lon = 0, 0
        cluster_centers.append((center_lat, center_lon))
        print(f"  í´ëŸ¬ìŠ¤í„° {i}: {len(cluster)}ê±´, ì¤‘ì‹¬=({center_lat:.4f}, {center_lon:.4f})")
    
    # Greedy ë§¤ì¹­: ê° í´ëŸ¬ìŠ¤í„°ì— ê°€ì¥ ì í•©í•œ ê¸°ì‚¬ ë°°ì •
    # ê¸°ì¤€: í¬ê¸° ë§¤ì¹­ + ê±°ë¦¬
    cluster_to_driver = {}
    used_drivers = set()
    
    # í´ëŸ¬ìŠ¤í„°ë¥¼ í¬ê¸° ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì²˜ë¦¬
    cluster_order = sorted(range(n_clusters), key=lambda i: -len(clusters[i]))
    
    for cluster_idx in cluster_order:
        cluster = clusters[cluster_idx]
        center = cluster_centers[cluster_idx]
        cluster_size = len(cluster)
        
        best_driver = None
        best_score = float('inf')
        
        for d_info in driver_info:
            if d_info['driver_idx'] in used_drivers:
                continue
            
            # ì ìˆ˜: |í´ëŸ¬ìŠ¤í„° í¬ê¸° - max_capa| * 1000 + ê±°ë¦¬
            size_diff = abs(cluster_size - d_info['max_capa'])
            dist = haversine(center[0], center[1], d_info['base_lat'], d_info['base_lng'])
            score = size_diff * 1000 + dist
            
            if score < best_score:
                best_score = score
                best_driver = d_info
        
        if best_driver:
            cluster_to_driver[cluster_idx] = best_driver['driver_idx']
            used_drivers.add(best_driver['driver_idx'])
            print(f"  í´ëŸ¬ìŠ¤í„° {cluster_idx} ({cluster_size}ê±´) â†’ {best_driver['driver'].name} (max_capa={best_driver['max_capa']})")
    
    return cluster_to_driver, driver_info


def trim_excess_nodes(clusters, cluster_to_driver, driver_info, df):
    """
    â˜… V11.4: ì´ˆê³¼ ë…¸ë“œ ì œê±° (ë¯¸ë°°ì • ì²˜ë¦¬) â˜…
    
    í´ëŸ¬ìŠ¤í„° ë‚´ ë…¸ë“œ ìˆ˜ > ê¸°ì‚¬ max_capaì¸ ê²½ìš°:
    - í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì—ì„œ ê°€ì¥ ë¨¼ ë…¸ë“œë¥¼ ë¯¸ë°°ì • ì²˜ë¦¬
    - ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ë¡œ ì´ì „í•˜ì§€ ì•ŠìŒ! (ê²½ê³„ ìœ ì§€)
    """
    
    print("\n=== 3ë‹¨ê³„: ì´ˆê³¼ ë…¸ë“œ ì²˜ë¦¬ ===")
    
    driver_max_capa = {d['driver_idx']: d['max_capa'] for d in driver_info}
    
    trimmed_clusters = []
    all_unassigned = []
    
    for cluster_idx, cluster in enumerate(clusters):
        if cluster_idx not in cluster_to_driver:
            trimmed_clusters.append(cluster)
            continue
        
        driver_idx = cluster_to_driver[cluster_idx]
        max_capa = driver_max_capa[driver_idx]
        
        if len(cluster) <= max_capa:
            trimmed_clusters.append(cluster)
            continue
        
        # ì´ˆê³¼ë¶„ ì œê±°
        excess = len(cluster) - max_capa
        
        # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬
        center_lat = np.mean([n['lat'] for n in cluster])
        center_lon = np.mean([n['lon'] for n in cluster])
        
        # ì¤‘ì‹¬ì—ì„œ ê±°ë¦¬ ê³„ì‚°
        nodes_with_dist = []
        for node in cluster:
            dist = haversine(center_lat, center_lon, node['lat'], node['lon'])
            nodes_with_dist.append((node, dist))
        
        # ê±°ë¦¬ìˆœ ì •ë ¬ (ê°€ê¹Œìš´ ê²ƒë¶€í„°)
        nodes_with_dist.sort(key=lambda x: x[1])
        
        # max_capaë§Œí¼ë§Œ ìœ ì§€, ë‚˜ë¨¸ì§€ëŠ” ë¯¸ë°°ì •
        kept = [n[0] for n in nodes_with_dist[:max_capa]]
        removed = [n[0] for n in nodes_with_dist[max_capa:]]
        
        trimmed_clusters.append(kept)
        all_unassigned.extend(removed)
        
        d_info = next(d for d in driver_info if d['driver_idx'] == driver_idx)
        print(f"  í´ëŸ¬ìŠ¤í„° {cluster_idx} ({d_info['driver'].name}): {len(cluster)} â†’ {len(kept)}ê±´ (ë¯¸ë°°ì • {len(removed)}ê±´)")
    
    print(f"  ì´ ë¯¸ë°°ì •: {len(all_unassigned)}ê±´")
    
    return trimmed_clusters, all_unassigned


def optimize_visit_order(df, nodes, start_lat, start_lon):
    """Nearest Neighbor TSP"""
    if not nodes:
        return []
    if len(nodes) == 1:
        return [nodes[0]['idx']]
    
    visited = []
    remaining = list(nodes)
    current_lat, current_lon = start_lat, start_lon
    
    while remaining:
        nearest_idx = min(range(len(remaining)), key=lambda i: haversine(
            current_lat, current_lon,
            remaining[i]['lat'], remaining[i]['lon']
        ))
        nearest = remaining.pop(nearest_idx)
        visited.append(nearest['idx'])
        current_lat, current_lon = nearest['lat'], nearest['lon']
    
    return visited


def calculate_route_distance(df, visit_order, start_lat, start_lon):
    """ê²½ë¡œ ê±°ë¦¬ ê³„ì‚°"""
    if not visit_order:
        return 0
    
    total = 0
    current_lat, current_lon = start_lat, start_lon
    
    for node_idx in visit_order:
        node_lat = float(df.iloc[node_idx]['lat'])
        node_lon = float(df.iloc[node_idx]['lon'])
        total += haversine(current_lat, current_lon, node_lat, node_lon)
        current_lat, current_lon = node_lat, node_lon
    
    return total


@app.get("/")
def read_root():
    return {
        "status": "active",
        "message": "VRP Engine V11.4 (Capacity-Aware Recursive Bisection)",
        "features": [
            "â˜… ê²½ë„/ìœ„ë„ ê¸°ì¤€ ì„  ê¸‹ê¸° (ë¬¼ë¦¬ì  ë¶„í• )",
            "â˜… capacity ë¹„ìœ¨ì— ë”°ë¥¸ ë¶„í•  í¬ê¸° ì¡°ì •",
            "â˜… í•œ ì˜ì—­ì´ ë‹¤ë¥¸ ì˜ì—­ì„ ê°ìŒ€ ìˆ˜ ì—†ìŒ",
            "â˜… ê²½ê³„ ì¡°ì • ì—†ìŒ (ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ë¡œ ì´ì „ X)",
            "â˜… ì´ˆê³¼ë¶„ì€ ë¯¸ë°°ì • ì²˜ë¦¬",
            "Nearest Neighbor TSP"
        ],
        "algorithm": "Capacity-Aware Recursive Bisection â†’ Driver Matching â†’ Trim Excess"
    }


@app.post("/optimize")
def optimize_routes(body: RequestBody):
    """
    â˜… V11.4: Capacity-Aware Recursive Bisection â˜…
    
    í•µì‹¬ ì›ì¹™:
    1. ê²½ë„/ìœ„ë„ ê¸°ì¤€ìœ¼ë¡œ "ì„ ì„ ê·¸ì–´" ë¶„í•  (ê°ì‹¸ê¸° ë¶ˆê°€ëŠ¥)
    2. ë¶„í•  í¬ê¸°ëŠ” max_capa ë¹„ìœ¨ì— ë§ê²Œ
    3. ì´ˆê³¼ë¶„ì€ ë¯¸ë°°ì • (ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ë¡œ ì´ì „ X)
    """
    
    try:
        # 1. ë°ì´í„° ì¤€ë¹„
        data = [loc.dict() for loc in body.locations]
        df = pd.DataFrame(data)
        df = df.reset_index(drop=True)
        
        num_locations = len(df)
        depot_idx = 0
        
        if num_locations < 2:
            return {"status": "error", "message": "Not enough locations"}
        
        # ê¸°ì‚¬ ì„¤ì •
        if body.drivers and len(body.drivers) > 0:
            drivers = body.drivers
        else:
            drivers = [
                Driver(id=f"driver_{i+1}", name=f"ê¸°ì‚¬ {i+1}", max_capa=DEFAULT_MAX_CAPA)
                for i in range(body.num_vehicles)
            ]
        
        num_drivers = len(drivers)
        
        # max_capa ë¦¬ìŠ¤íŠ¸ (ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬)
        capacities = sorted([d.max_capa or DEFAULT_MAX_CAPA for d in drivers], reverse=True)
        total_max_capa = sum(capacities)
        total_calls = num_locations - 1
        
        print(f"\n{'='*50}")
        print(f"VRP V11.4 - Capacity-Aware Recursive Bisection")
        print(f"{'='*50}")
        print(f"ì´ ì½œ: {total_calls}ê±´, ìˆ˜ìš©ëŸ‰: {total_max_capa}ê±´")
        print(f"Capacities (ì •ë ¬): {capacities}")
        
        if 'weight' not in df.columns:
            df['weight'] = DEFAULT_WEIGHT_KG
        df['weight'] = pd.to_numeric(df['weight'], errors='coerce').fillna(DEFAULT_WEIGHT_KG).astype(int)
        
        # ë…¸ë“œ ë°ì´í„° ì¤€ë¹„ (depot ì œì™¸)
        nodes_data = []
        for i in range(len(df)):
            if i == depot_idx:
                continue
            nodes_data.append({
                'idx': i,
                'lat': float(df.iloc[i]['lat']),
                'lon': float(df.iloc[i]['lon']),
                'weight': int(df.iloc[i]['weight'])
            })
        
        # 2. Capacity-Aware Recursive Bisection
        print("\n=== 1ë‹¨ê³„: Capacity-Aware Bisection ===")
        clusters = capacity_aware_bisection(nodes_data, capacities)
        
        print(f"\n  ë¶„í•  ê²°ê³¼: {[len(c) for c in clusters]}")
        
        # 3. í´ëŸ¬ìŠ¤í„°-ê¸°ì‚¬ ë§¤ì¹­
        cluster_to_driver, driver_info = assign_clusters_to_drivers(clusters, drivers, df, depot_idx)
        
        # 4. ì´ˆê³¼ ë…¸ë“œ ì œê±°
        trimmed_clusters, unassigned_nodes = trim_excess_nodes(clusters, cluster_to_driver, driver_info, df)
        
        # 5. ê²°ê³¼ ìƒì„±
        print("\n=== 4ë‹¨ê³„: ë°©ë¬¸ ìˆœì„œ ìµœì í™” ===")
        
        results = []
        stats = []
        total_distance = 0
        
        driver_info_map = {d['driver_idx']: d for d in driver_info}
        
        for cluster_idx, cluster in enumerate(trimmed_clusters):
            if cluster_idx not in cluster_to_driver:
                continue
            
            driver_idx = cluster_to_driver[cluster_idx]
            d_info = driver_info_map[driver_idx]
            driver = d_info['driver']
            max_capa = d_info['max_capa']
            base_lat = d_info['base_lat']
            base_lng = d_info['base_lng']
            
            if not cluster:
                stats.append({
                    "driver_id": driver.id,
                    "driver_name": driver.name,
                    "call_count": 0,
                    "max_capa": max_capa,
                    "total_weight_kg": 0,
                    "distance_km": 0,
                    "status": "âš ï¸ ë°°ì • ì—†ìŒ"
                })
                continue
            
            visit_order = optimize_visit_order(df, cluster, base_lat, base_lng)
            route_distance = calculate_route_distance(df, visit_order, base_lat, base_lng)
            total_distance += route_distance
            
            route_weight = 0
            for order, node_idx in enumerate(visit_order, 1):
                node = df.iloc[node_idx]
                node_weight = int(node['weight'])
                route_weight += node_weight
                
                results.append({
                    "id": str(node['id']),
                    "driver_id": driver.id,
                    "driver_name": driver.name,
                    "visit_order": order,
                    "weight_kg": node_weight,
                    "cumulative_weight_kg": route_weight
                })
            
            call_count = len(visit_order)
            status = "ì •ìƒ" if call_count <= max_capa else f"ğŸš¨ ì´ˆê³¼"
            
            stats.append({
                "driver_id": driver.id,
                "driver_name": driver.name,
                "call_count": call_count,
                "max_capa": max_capa,
                "total_weight_kg": route_weight,
                "distance_km": round(route_distance, 2),
                "status": status
            })
            
            print(f"  {driver.name}: {call_count}ê±´, {route_distance:.1f}km")
        
        violations = [s for s in stats if s['call_count'] > s['max_capa']]
        unassigned_ids = [str(df.iloc[n['idx']]['id']) for n in unassigned_nodes]
        
        print(f"\n{'='*50}")
        print(f"ì™„ë£Œ: ë°°ì • {len(results)}ê±´, ë¯¸ë°°ì • {len(unassigned_nodes)}ê±´")
        print(f"{'='*50}")
        
        return {
            "status": "success",
            "updates": results,
            "statistics": stats,
            "summary": {
                "total_locations": total_calls,
                "total_assigned": len(results),
                "unassigned": len(unassigned_nodes),
                "unassigned_ids": unassigned_ids,
                "total_distance_km": round(total_distance, 2)
            },
            "optimization_info": {
                "algorithm": "V11.4: Capacity-Aware Recursive Bisection",
                "max_capa_violations": len(violations),
                "cluster_overlap": 0,
                "note": "ê²½ë„/ìœ„ë„ ê¸°ì¤€ ì„  ê¸‹ê¸°ë¡œ ì˜ì—­ ë¶„í• , ê°ì‹¸ê¸° ë¶ˆê°€ëŠ¥"
            }
        }
        
    except Exception as e:
        traceback.print_exc()
        return {"status": "error", "message": str(e)}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
